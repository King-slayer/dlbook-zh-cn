\chapter{应用}
\label{ch:applications}

在这一章，我们描述如何使用深度学习来解决在计算机视觉、语音识别、自然语言处理和其
它商业性领域的应用。首先，我们讨论最重要的人工智能应用所需的大规模神经网络实现。
接下来，我们回顾几个深度学习已经被用于解决问题的特殊应用领域。虽然深度学习的一个
目标是设计能够解决各种各样任务的算法，到目前为止还需要一定程度的专业化。例如，视
觉任务每个样本需要处理大量输入特征（像素）。语言任务每个输入特征需要对大量可能值
（词汇表中的单词）建模。

\section{大规模深度学习}
\label{sec:large_scale_deep_learning}

深度学习基于联结主义的哲学：虽然单个的生物神经元或者机器学习模型中的单个特征并不
% See https://en.wikipedia.org/wiki/Connectionism
智能，大量神经元或者特征的共同作用可以表现出智能行为。强调这一事实非常重要，神经
元的数量必须是\emph{大量的}。对于提高神经网络准确性和任务复杂度~——~那些从 80 年代
至今解决的任务~——~的一个关键因素，是我们使用的网络规模上引人注目的增长。正如我们
在~\ref{subsec:increasing_model_sizes} 节中看到的，网络规模在过去三十年间以指数方
式增长，然而人工神经网络仅仅和昆虫的神经系统一样大。

因为神经网络的规模是非常重要的，深度学习需要高性能的硬件和软件基础。

\subsection{快速的 CPU 执行}
\label{subsec:fast_cpu_implementations}

传统上，神经网络利用一台机器的 CPU 训练。今天，这种方法被认为是不够的。我们现在主
要使用GPU 运算或者多机联网的 CPU。在移到这些昂贵的装置前，研究人员努力证明 CPU 无
法完成神经网络需要的很高的计算工作量。

如何执行高效的数字 CPU 代码的描述超出了这本书的范围，但我们在这里强调，仔细为特定
的 CPU 家族的执行可以产生较大的改进。例如，在 2011 年，最好的 CPU 在使用定点运算
时，运行神经网络的工作量要快于使用浮点运算。通过创造一个仔细调试的定点执
行，Vanhoucke \textit{et al.}（2011） 取得了超过一个强大的浮点系统的三倍提速。每
个新的 CPU 型号有不同的性能特点，所以有时浮点执行也能够更快。重要的原则是，对数值
计算程序的仔细的专门处理，可以获得很大的回报。其他策略，除了选择是否使用定点或浮
点，还包括优化数据结构，以避免高速缓存块未命中（cache misses）和使用矢量指令。许
多机器学习的研究人员忽视了这些执行细节，但当执行的性能限制模型的大小时，模型的准
确性受到影响。

\subsection{GPU 执行}
\label{subsec:gpu_implementations}

大部分现代神经网络的执行基于图形处理单元。图形处理单元（GPU）是最初为图形应用开发
的专门的硬件组件。视频游戏系统的消费者市场刺激了图形图形处理硬件的发展。好的视频
游戏系统所需的性能特性结果发现对神经网络同样有益。

视频游戏渲染需要并行快速地执行很多操作。角色和环境模型以三维的顶点坐标列表的形式
指定。图形卡必须执行许多顶点的矩阵乘除，同时并行地将这些三维坐标转换到二维的屏幕
坐标。图形卡必须在每个像素执行许多计算，同时并行地确定每个像素的颜色。在这两种情
况下，计算都相当简单，和一个 CPU 通常遇到的计算工作量相比，并不涉及大量的分支。例
如，在相同的刚性物体中的每个顶点会被相同的矩阵相乘；没有必要每个顶点用 {\serif
  if} 声明求值来确定乘以哪个矩阵。这些计算彼此间也完全无关，这样可以很容易并行化。
这些计算也涉及处理大量的内存缓存，包括描述每个渲染物体纹理（颜色图案）的位图。结
合在一起，这导致图形卡被设计成具有高度的并行性和高内存带宽，其代价是相对于传
统 CPU 有一个更低的时钟速度和更少的分支能力。

神经网络算法需要和上面描述的实时图形算法相同的性能特性。神经网络通常涉及数量庞大
的参数、激活值和梯度值的缓存，其中每个都必须在每一步的训练中被完整更新。这些缓存
大到足够超出传统的桌面计算机的高速缓冲区（cache）而崩溃。GPU， 由于它们的高内存带
宽，提供了一个超过 CPU 的不可抗拒的优势。神经网络训练算法通常不涉及很多分支或者复
杂控制，所以它们适用于 GPU 硬件。
